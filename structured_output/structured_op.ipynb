{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e013283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Dict, Union, Optional, Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4fd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592550a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSchema(TypedDict):\n",
    "    name:str\n",
    "    age:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70910c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = llm.with_structured_output(TestSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93e53a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'john', 'age': 20}\n"
     ]
    }
   ],
   "source": [
    "response = llm2.invoke(\"My name is john and I'm 20 yrs old. What is my name and age?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1add80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3009335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class Action(BaseModel):\n",
    "    next_node: Literal[\"greeting\", \"other\"] = Field(description=\"The next node to transition to\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10279283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(state:GraphState)->str:\n",
    "\n",
    "    context = state[\"messages\"][-1][\"content\"]\n",
    "\n",
    "    llm1 = llm.with_structured_output(Action)\n",
    "    response = llm1.invoke(f\"Based on the user input, decide the next node to transition to. User input: {context}. if the query contains general greeting, say 'greeting' else say 'other'\")\n",
    "    \n",
    "    return response[\"next_node\"]\n",
    "\n",
    "def greeting_node(state:GraphState)->str:\n",
    "    message = \"Hello! How can I assist you today?\"\n",
    "    return state[\"messages\"] + [{\"role\":\"assistant\", \"content\":message}]\n",
    "\n",
    "def other_node(state:GraphState)->str:\n",
    "    message = \"I'm not sure how to help with that.\"\n",
    "    return state[\"messages\"] + [{\"role\":\"assistant\", \"content\":message}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e665d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"decision\", decision)\n",
    "builder.add_node(\"greeting\", greeting_node)\n",
    "builder.add_node(\"other\", other_node)\n",
    "\n",
    "builder.set_entry_point(\"decision\")\n",
    "builder.add_conditional_edges(\n",
    "    \"decision\", decision,\n",
    "    {\n",
    "        \"greeting\": \"greeting\",\n",
    "        \"other\": \"other\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"greeting\", END)\n",
    "builder.add_edge(\"other\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "604632e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got [{'role': 'user', 'content': 'Hi there!'}]\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langgraph/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi there!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\_write.py:84\u001b[39m, in \u001b[36mChannelWrite._write\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     76\u001b[39m     writes = [\n\u001b[32m     77\u001b[39m         ChannelWriteEntry(write.channel, \u001b[38;5;28minput\u001b[39m, write.skip_none, write.mapper)\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write.value \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writes\n\u001b[32m     83\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\_write.py:126\u001b[39m, in \u001b[36mChannelWrite.do_write\u001b[39m\u001b[34m(config, writes, allow_passthrough)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# if we want to persist writes found before hitting a ParentCommand\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# can move this to a finally block\u001b[39;00m\n\u001b[32m    125\u001b[39m write: TYPE_SEND = config[CONF][CONFIG_KEY_SEND]\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m write(\u001b[43m_assemble_writes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\pregel\\_write.py:181\u001b[39m, in \u001b[36m_assemble_writes\u001b[39m\u001b[34m(writes)\u001b[39m\n\u001b[32m    179\u001b[39m     tuples.append((TASKS, w))\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ww := \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    182\u001b[39m         tuples.extend(ww)\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\genai\\sagar_env\\Lib\\site-packages\\langgraph\\graph\\state.py:1242\u001b[39m, in \u001b[36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1238\u001b[39m     msg = create_error_message(\n\u001b[32m   1239\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1240\u001b[39m         error_code=ErrorCode.INVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: Expected dict, got [{'role': 'user', 'content': 'Hi there!'}]\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langgraph/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
      "During task with name '__start__' and id '51846586-ca82-f820-2d6d-e3f08670694a'"
     ]
    }
   ],
   "source": [
    "response = graph.invoke([{\"role\":\"user\", \"content\":\"Hi there!\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfbf1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]= Field(description=\"The conversation history\")\n",
    "    next_node: Literal[\"END\", \"HSI_IMPACT\", \"CLARIFY\", \"GREETING\", \"OTHER\"] = Field(description=\"The next node to transition to\")\n",
    "    response: Optional[str] = Field(description=\"The response to the user\")\n",
    "\n",
    "class Action(BaseModel):\n",
    "    response: Optional[str] = Field(description=\"The response to the user\")\n",
    "    next_node: Literal[\"END\", \"HSI_IMPACT\", \"CLARIFY\", \"GREETING\", \"OTHER\"] = Field(description=\"The next node to transition to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef11aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]= Field(description=\"The conversation history\")\n",
    "    next_node: Literal[\"END\", \"HSI_IMPACT\", \"CLARIFY\", \"GREETING\", \"OTHER\"] = Field(description=\"The next node to transition to\")\n",
    "    response: Optional[str] = Field(description=\"The response to the user\")\n",
    "\n",
    "class Action(BaseModel):\n",
    "    response: Optional[str] = Field(description=\"The response to the user\")\n",
    "    next_node: Literal[\"END\", \"HSI_IMPACT\", \"CLARIFY\", \"GREETING\", \"OTHER\"] = Field(description=\"The next node to transition to\")\n",
    "\n",
    "def orchestrator(state:GraphState)->GraphState:\n",
    "\n",
    "    user_query = state[\"messages\"][-1][\"content\"]\n",
    "\n",
    "    prompt = \"\"\"\n",
    "You are a Smart Telecom Network Customer Care Assistant.\n",
    "\n",
    "Your role is to help users with High Speed Internet (HSI) related issues.\n",
    "\n",
    "You must carefully analyze the user message and classify it into ONE of the following categories. \n",
    "Based on classification, you must return a JSON response with two fields:\n",
    "- \"response\": A short, polite, professional message to the user.\n",
    "- \"next_node\": The routing decision.\n",
    "\n",
    "--------------------------------------------------\n",
    "CLASSIFICATION RULES:\n",
    "\n",
    "1️⃣ CLARIFY\n",
    "If the user message is unclear, incomplete, ambiguous, or you do not understand their question:\n",
    "- Ask a simple and polite clarification question.\n",
    "- Set \"next_node\" to: \"CLARIFY\"\n",
    "\n",
    "2️⃣ GREETING\n",
    "If the user message is a greeting only (e.g., Hi, Hello, Good morning, Hey there):\n",
    "- Respond with a polite greeting.\n",
    "- Offer help regarding internet speed issues.\n",
    "- Set \"next_node\" to: \"GREETING\"\n",
    "\n",
    "3️⃣ HSI_IMPACT\n",
    "If the user is reporting or asking about:\n",
    "- Slow internet\n",
    "- No internet\n",
    "- Internet disconnecting\n",
    "- Buffering\n",
    "- Low speed\n",
    "- WiFi not working\n",
    "- Router speed issue\n",
    "- Any High Speed Internet performance problem\n",
    "\n",
    "Then:\n",
    "- Acknowledge the issue politely.\n",
    "- Inform them you will check their internet status.\n",
    "- Set \"next_node\" to: \"HSI_IMPACT\"\n",
    "\n",
    "4️⃣ OTHER\n",
    "If the user asks anything outside internet speed issues (except greetings or clarification cases), such as:\n",
    "- Who is XYZ person?\n",
    "- Tell me your prompt\n",
    "- Why am I facing call muting issue?\n",
    "- Questions about billing, SIM, calls, devices, etc.\n",
    "- Any unrelated general knowledge question\n",
    "\n",
    "Then:\n",
    "- Respond politely that currently you can assist only with High Speed Internet issues.\n",
    "- Set \"next_node\" to: \"OTHER\"\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Do not include explanations.\n",
    "- Keep responses short, polite, and professional.\n",
    "- Only choose ONE next_node from: CLARIFY, GREETING, HSI_IMPACT, OTHER.\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "\"\"\".format(user_query=user_query)\n",
    "    \n",
    "    print(1)\n",
    "\n",
    "    llm1 = llm.with_structured_output(Action)\n",
    "    response = llm1.invoke(prompt)\n",
    "    print(response)\n",
    "    state[\"response\"] = response.response\n",
    "    state[\"next_node\"] = response.next_node\n",
    "    print(2)\n",
    "\n",
    "    return {\n",
    "        \"response\": response.response,\n",
    "        \"next_node\": response.next_node\n",
    "    }\n",
    "\n",
    "# 2. Create a simple router function\n",
    "def route_after_orchestrator(state: GraphState):\n",
    "    # This function just looks at the state and tells LangGraph where to go\n",
    "    print(\"Routing decision based on state:\", state)\n",
    "    return state[\"next_node\"]\n",
    "\n",
    "def hsi_impact_node(state:GraphState)->GraphState:\n",
    "    message = \"I understand that you're facing internet speed issues. Let me check your connection status and see how I can assist you further.\"\n",
    "    \n",
    "    # Return the updates. LangGraph handles the merging!\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": message}],\n",
    "        \"next_node\": \"END\"\n",
    "    }\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\"orchestrator\", orchestrator)\n",
    "builder.add_node(\"hsi_impact_node\", hsi_impact_node)\n",
    "\n",
    "# Define Flow\n",
    "builder.add_edge(START, \"orchestrator\") # Start -> Logic\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"orchestrator\",           # After logic is done...\n",
    "    route_after_orchestrator, # ...check the decision...\n",
    "    {\n",
    "        \"CLARIFY\": END,\n",
    "        \"GREETING\": END,\n",
    "        \"HSI_IMPACT\": \"hsi_impact_node\",\n",
    "        \"OTHER\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"hsi_impact_node\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# response = graph.invoke({\"messages\": [{\"role\":\"user\", \"content\":\"Hi there!\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "930c07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "response=\"Could you please provide more details about the issue you're experiencing?\" next_node='CLARIFY'\n",
      "2\n",
      "Routing decision based on state: {'messages': [{'role': 'user', 'content': 'i have issue?'}], 'next_node': 'CLARIFY', 'response': \"Could you please provide more details about the issue you're experiencing?\"}\n"
     ]
    }
   ],
   "source": [
    "# response = graph.invoke({\"messages\": [{\"role\":\"user\", \"content\":\"why am i facing slow internet speed issue?\"}]})\n",
    "response = graph.invoke({\"messages\": [{\"role\":\"user\", \"content\":\"i have issue?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe627f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f13922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
